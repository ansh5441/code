# CorpusHeadline = tm_map(CorpusHeadline, removeWords, stopwords("english"))
# CorpusHeadline = tm_map(CorpusHeadline, stemDocument)
# dtm = DocumentTermMatrix(CorpusHeadline)
# sparse = removeSparseTerms(dtm, 0.99)
# HeadlineWords = as.data.frame(as.matrix(sparse))
# colnames(HeadlineWords) = make.names(colnames(HeadlineWords))
# HeadlineWordsTrain = head(HeadlineWords, nrow(NewsTrain))
# HeadlineWordsTest = tail(HeadlineWords, nrow(NewsTest))
# Create a corpus from the snippet variable
CorpusSnippet = Corpus(VectorSource(c(NewsTrain$Snippet, NewsTest$Snippet)))
CorpusSnippet = tm_map(CorpusSnippet, tolower)
CorpusSnippet = tm_map(CorpusSnippet, PlainTextDocument)
CorpusSnippet = tm_map(CorpusSnippet, removePunctuation)
CorpusSnippet = tm_map(CorpusSnippet, removeWords, stopwords("english"))
CorpusSnippet = tm_map(CorpusSnippet, stemDocument)
dtmSnippet = DocumentTermMatrix(CorpusSnippet)
sparseSnippet = removeSparseTerms(dtmSnippet, 0.99)
SnippetWords = as.data.frame(as.matrix(sparseSnippet))
colnames(SnippetWords) = make.names(colnames(SnippetWords))
SnippetWordsTrain = head(SnippetWords, nrow(NewsTrain))
SnippetWordsTest = tail(SnippetWords, nrow(NewsTest))
SnippetWordsTrain$Popular = NewsTrain$Popular
SnippetWordsTest$Popular = NewsTest$Popular
SnippetWordsTrain$WordCount = NewsTrain$WordCount
SnippetWordsTest$WordCount = NewsTest$WordCount
SnippetWordsTrain$NewsDesk = NewsTrain$NewsDesk
SnippetWordsTest$NewsDesk = NewsTest$NewsDesk
SnippetWordsTrain$SectionName = NewsTrain$SectionName
SnippetWordsTest$SectionName = NewsTest$SectionName
SnippetWordsTrain$SubsectionName = NewsTrain$SubsectionName
SnippetWordsTest$SubsectionName = NewsTest$SubsectionName
SnippetWordsTrain$Weekday = NewsTrain$Weekday
SnippetWordsTest$NewsDesk = NewsTest$NewsDesk
# CorpusAbstract = Corpus(VectorSource(c(NewsTrain$Abstract, NewsTest$Abstract)))
# CorpusAbstract = tm_map(CorpusAbstract, tolower)
# CorpusAbstract = tm_map(CorpusAbstract, PlainTextDocument)
# CorpusAbstract = tm_map(CorpusAbstract, removePunctuation)
# CorpusAbstract = tm_map(CorpusAbstract, removeWords, stopwords("english"))
# CorpusAbstract = tm_map(CorpusAbstract, stemDocument)
# dtmAbstract = DocumentTermMatrix(CorpusAbstract)
# sparseAbstract = removeSparseTerms(dtmAbstract, 0.99)
# AbstractWords = as.data.frame(as.matrix(sparseAbstract))
# colnames(AbstractWords) = make.names(colnames(AbstractWords))
# AbstractWordsTrain = head(AbstractWords, nrow(NewsTrain))
# AbstractWordsTest = tail(AbstractWords, nrow(NewsTest))
# Create The Model
SimpleMod = glm(Popular ~ WordCount, data=SnippetWordsTrain, family=binomial)
# And then make predictions on the test set:
PredTest = predict(SimpleMod, newdata=NewsTest, type="response")
PredTrain = predict(SimpleMod, newdata=NewsTrain, type="response")
table(PredTrain>0.5, NewsTrain$Popular)
# Prepare a submission file for Kaggle
MySubmission = data.frame(UniqueID = NewsTest$UniqueID, Probability1 = PredTest)
write.csv(MySubmission, "SubmissionSimpleLog2.csv", row.names=FALSE)
library(tm)
# Read the data into R
NewsTrain = read.csv("NYTimesBlogTrain.csv", stringsAsFactors=FALSE)
NewsTest = read.csv("NYTimesBlogTest.csv", stringsAsFactors=FALSE)
# Preprocess dates
NewsTrain$PubDate = strptime(NewsTrain$PubDate, "%Y-%m-%d %H:%M:%S")
NewsTrain$Weekday = NewsTrain$PubDate$wday
NewsTest$PubDate = strptime(NewsTest$PubDate, "%Y-%m-%d %H:%M:%S")
NewsTest$Weekday = NewsTest$PubDate$wday
# Create factor variables
NewsTrain$NewsDesk = as.factor(NewsTrain$NewsDesk)
NewsTest$NewsDesk = as.factor(NewsTest$NewsDesk)
NewsTrain$SectionName = as.factor(NewsTrain$SectionName)
NewsTest$SectionName = as.factor(NewsTest$SectionName)
NewsTrain$SubsectionName = as.factor(NewsTrain$SubsectionName)
NewsTest$SubsectionName = as.factor(NewsTest$SubsectionName)
# Create a corpus from the headline variable
# CorpusHeadline = Corpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
# CorpusHeadline = tm_map(CorpusHeadline, tolower)
# CorpusHeadline = tm_map(CorpusHeadline, PlainTextDocument)
# CorpusHeadline = tm_map(CorpusHeadline, removePunctuation)
# CorpusHeadline = tm_map(CorpusHeadline, removeWords, stopwords("english"))
# CorpusHeadline = tm_map(CorpusHeadline, stemDocument)
# dtm = DocumentTermMatrix(CorpusHeadline)
# sparse = removeSparseTerms(dtm, 0.99)
# HeadlineWords = as.data.frame(as.matrix(sparse))
# colnames(HeadlineWords) = make.names(colnames(HeadlineWords))
# HeadlineWordsTrain = head(HeadlineWords, nrow(NewsTrain))
# HeadlineWordsTest = tail(HeadlineWords, nrow(NewsTest))
# Create a corpus from the snippet variable
CorpusSnippet = Corpus(VectorSource(c(NewsTrain$Snippet, NewsTest$Snippet)))
CorpusSnippet = tm_map(CorpusSnippet, tolower)
CorpusSnippet = tm_map(CorpusSnippet, PlainTextDocument)
CorpusSnippet = tm_map(CorpusSnippet, removePunctuation)
CorpusSnippet = tm_map(CorpusSnippet, removeWords, stopwords("english"))
CorpusSnippet = tm_map(CorpusSnippet, stemDocument)
dtmSnippet = DocumentTermMatrix(CorpusSnippet)
sparseSnippet = removeSparseTerms(dtmSnippet, 0.99)
SnippetWords = as.data.frame(as.matrix(sparseSnippet))
colnames(SnippetWords) = make.names(colnames(SnippetWords))
SnippetWordsTrain = head(SnippetWords, nrow(NewsTrain))
SnippetWordsTest = tail(SnippetWords, nrow(NewsTest))
SnippetWordsTrain$Popular = NewsTrain$Popular
SnippetWordsTest$Popular = NewsTest$Popular
SnippetWordsTrain$WordCount = NewsTrain$WordCount
SnippetWordsTest$WordCount = NewsTest$WordCount
SnippetWordsTrain$NewsDesk = NewsTrain$NewsDesk
SnippetWordsTest$NewsDesk = NewsTest$NewsDesk
SnippetWordsTrain$SectionName = NewsTrain$SectionName
SnippetWordsTest$SectionName = NewsTest$SectionName
SnippetWordsTrain$SubsectionName = NewsTrain$SubsectionName
SnippetWordsTest$SubsectionName = NewsTest$SubsectionName
SnippetWordsTrain$Weekday = NewsTrain$Weekday
SnippetWordsTest$NewsDesk = NewsTest$NewsDesk
# CorpusAbstract = Corpus(VectorSource(c(NewsTrain$Abstract, NewsTest$Abstract)))
# CorpusAbstract = tm_map(CorpusAbstract, tolower)
# CorpusAbstract = tm_map(CorpusAbstract, PlainTextDocument)
# CorpusAbstract = tm_map(CorpusAbstract, removePunctuation)
# CorpusAbstract = tm_map(CorpusAbstract, removeWords, stopwords("english"))
# CorpusAbstract = tm_map(CorpusAbstract, stemDocument)
# dtmAbstract = DocumentTermMatrix(CorpusAbstract)
# sparseAbstract = removeSparseTerms(dtmAbstract, 0.99)
# AbstractWords = as.data.frame(as.matrix(sparseAbstract))
# colnames(AbstractWords) = make.names(colnames(AbstractWords))
# AbstractWordsTrain = head(AbstractWords, nrow(NewsTrain))
# AbstractWordsTest = tail(AbstractWords, nrow(NewsTest))
# Create The Model
SimpleMod = glm(Popular ~ ., data=SnippetWordsTrain, family=binomial)
# And then make predictions on the test set:
PredTest = predict(SimpleMod, newdata=NewsTest, type="response")
PredTrain = predict(SimpleMod, newdata=NewsTrain, type="response")
table(PredTrain>0.5, NewsTrain$Popular)
# Prepare a submission file for Kaggle
MySubmission = data.frame(UniqueID = NewsTest$UniqueID, Probability1 = PredTest)
write.csv(MySubmission, "SubmissionSimpleLog2.csv", row.names=FALSE)
# Create The Model
SimpleMod = glm(Popular ~ ., data=SnippetWordsTrain, family=binomial)
# And then make predictions on the test set:
PredTest = predict(SimpleMod, newdata=SnippetWordsTest, type="response")
PredTrain = predict(SimpleMod, newdata=SnippetWordsTrain, type="response")
table(PredTrain>0.5, SnippetWordsTrain$Popular)
# Prepare a submission file for Kaggle
MySubmission = data.frame(UniqueID = SnippetWordsTest$UniqueID, Probability1 = PredTest)
write.csv(MySubmission, "SubmissionSimpleLog2.csv", row.names=FALSE)
summary(SimpleMod)
MySubmission = data.frame(UniqueID = NewsTest$UniqueID, Probability1 = PredTest)
write.csv(MySubmission, "SubmissionSimpleLog2.csv", row.names=FALSE)
SimpleMod = rpart(Popular ~ ., data=SnippetWordsTrain, family=binomial)
# And then make predictions on the test set:
PredTest = predict(SimpleMod, newdata=SnippetWordsTest, type="response")
PredTrain = predict(SimpleMod, newdata=SnippetWordsTrain, type="response")
table(PredTrain>0.5, SnippetWordsTrain$Popular)
# Prepare a submission file for Kaggle
MySubmission = data.frame(UniqueID = NewsTest$UniqueID, Probability1 = PredTest)
write.csv(MySubmission, "SubmissionSimpleLog2.csv", row.names=FALSE)
library(rpart)
SimpleMod = rpart(Popular ~ ., data=SnippetWordsTrain, family=binomial)
# And then make predictions on the test set:
PredTest = predict(SimpleMod, newdata=SnippetWordsTest, type="response")
PredTrain = predict(SimpleMod, newdata=SnippetWordsTrain, type="response")
table(PredTrain>0.5, SnippetWordsTrain$Popular)
# Prepare a submission file for Kaggle
MySubmission = data.frame(UniqueID = NewsTest$UniqueID, Probability1 = PredTest)
write.csv(MySubmission, "SubmissionSimpleLog2.csv", row.names=FALSE)
library(tm)
library(rpart)
# Read the data into R
NewsTrain = read.csv("NYTimesBlogTrain.csv", stringsAsFactors=FALSE)
NewsTest = read.csv("NYTimesBlogTest.csv", stringsAsFactors=FALSE)
# Preprocess dates
NewsTrain$PubDate = strptime(NewsTrain$PubDate, "%Y-%m-%d %H:%M:%S")
NewsTrain$Weekday = NewsTrain$PubDate$wday
NewsTest$PubDate = strptime(NewsTest$PubDate, "%Y-%m-%d %H:%M:%S")
NewsTest$Weekday = NewsTest$PubDate$wday
# Create factor variables
NewsTrain$NewsDesk = as.factor(NewsTrain$NewsDesk)
NewsTest$NewsDesk = as.factor(NewsTest$NewsDesk)
NewsTrain$SectionName = as.factor(NewsTrain$SectionName)
NewsTest$SectionName = as.factor(NewsTest$SectionName)
NewsTrain$SubsectionName = as.factor(NewsTrain$SubsectionName)
NewsTest$SubsectionName = as.factor(NewsTest$SubsectionName)
# Create a corpus from the headline variable
# CorpusHeadline = Corpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
# CorpusHeadline = tm_map(CorpusHeadline, tolower)
# CorpusHeadline = tm_map(CorpusHeadline, PlainTextDocument)
# CorpusHeadline = tm_map(CorpusHeadline, removePunctuation)
# CorpusHeadline = tm_map(CorpusHeadline, removeWords, stopwords("english"))
# CorpusHeadline = tm_map(CorpusHeadline, stemDocument)
# dtm = DocumentTermMatrix(CorpusHeadline)
# sparse = removeSparseTerms(dtm, 0.99)
# HeadlineWords = as.data.frame(as.matrix(sparse))
# colnames(HeadlineWords) = make.names(colnames(HeadlineWords))
# HeadlineWordsTrain = head(HeadlineWords, nrow(NewsTrain))
# HeadlineWordsTest = tail(HeadlineWords, nrow(NewsTest))
# Create a corpus from the snippet variable
CorpusSnippet = Corpus(VectorSource(c(NewsTrain$Snippet, NewsTest$Snippet)))
CorpusSnippet = tm_map(CorpusSnippet, tolower)
CorpusSnippet = tm_map(CorpusSnippet, PlainTextDocument)
CorpusSnippet = tm_map(CorpusSnippet, removePunctuation)
CorpusSnippet = tm_map(CorpusSnippet, removeWords, stopwords("english"))
CorpusSnippet = tm_map(CorpusSnippet, stemDocument)
dtmSnippet = DocumentTermMatrix(CorpusSnippet)
sparseSnippet = removeSparseTerms(dtmSnippet, 0.99)
SnippetWords = as.data.frame(as.matrix(sparseSnippet))
colnames(SnippetWords) = make.names(colnames(SnippetWords))
SnippetWordsTrain = head(SnippetWords, nrow(NewsTrain))
SnippetWordsTest = tail(SnippetWords, nrow(NewsTest))
SnippetWordsTrain$Popular = NewsTrain$Popular
SnippetWordsTest$Popular = NewsTest$Popular
SimpleMod = rpart(Popular ~ ., data=SnippetWordsTrain, family=binomial)
# And then make predictions on the test set:
PredTest = predict(SimpleMod, newdata=SnippetWordsTest, type="response")
PredTrain = predict(SimpleMod, newdata=SnippetWordsTrain, type="response")
table(PredTrain>0.5, SnippetWordsTrain$Popular)
# Prepare a submission file for Kaggle
MySubmission = data.frame(UniqueID = NewsTest$UniqueID, Probability1 = PredTest)
write.csv(MySubmission, "SubmissionSimpleLog2.csv", row.names=FALSE)
SimpleMod = rpart(Popular ~ ., data=SnippetWordsTrain)
# And then make predictions on the test set:
PredTest = predict(SimpleMod, newdata=SnippetWordsTest, type="response")
PredTrain = predict(SimpleMod, newdata=SnippetWordsTrain, type="response")
table(PredTrain>0.5, SnippetWordsTrain$Popular)
# Prepare a submission file for Kaggle
MySubmission = data.frame(UniqueID = NewsTest$UniqueID, Probability1 = PredTest)
write.csv(MySubmission, "SubmissionSimpleLog2.csv", row.names=FALSE)
str(SnippetWordsTrain)
SimpleMod = rpart(Popular ~ ., data=SnippetWordsTrain)
PredTest = predict(SimpleMod, newdata=SnippetWordsTest, type="response")
PredTest = predict(SimpleMod, newdata=SnippetWordsTest)
MySubmission = data.frame(UniqueID = NewsTest$UniqueID, Probability1 = PredTest)
write.csv(MySubmission, "SubmissionSimpleLog3.csv", row.names=FALSE)
PredTrain = predict(SimpleMod, newdata=SnippetWordsTrain)
table(PredTrain>0.5, SnippetWordsTrain$Popular)
SimpleMod = rpart(Popular ~ ., data=SnippetWordsTrain)
# And then make predictions on the test set:
PredTest = predict(SimpleMod, newdata=SnippetWordsTest, type="class")
PredTrain = predict(SimpleMod, newdata=SnippetWordsTrain, type="class")
table(PredTrain>0.5, SnippetWordsTrain$Popular)
# Prepare a submission file for Kaggle
MySubmission = data.frame(UniqueID = NewsTest$UniqueID, Probability1 = PredTest)
write.csv(MySubmission, "SubmissionSimpleLog2.csv", row.names=FALSE)
PredTest = predict(SimpleMod, newdata=SnippetWordsTest)
PredTrain = predict(SimpleMod, newdata=SnippetWordsTrain)
table(PredTrain>0.5, SnippetWordsTrain$Popular)
library(tm)
library(rpart)
# Read the data into R
NewsTrain = read.csv("NYTimesBlogTrain.csv", stringsAsFactors=FALSE)
NewsTest = read.csv("NYTimesBlogTest.csv", stringsAsFactors=FALSE)
# Preprocess dates
NewsTrain$PubDate = strptime(NewsTrain$PubDate, "%Y-%m-%d %H:%M:%S")
NewsTrain$Weekday = NewsTrain$PubDate$wday
NewsTest$PubDate = strptime(NewsTest$PubDate, "%Y-%m-%d %H:%M:%S")
NewsTest$Weekday = NewsTest$PubDate$wday
# Create factor variables
NewsTrain$NewsDesk = as.factor(NewsTrain$NewsDesk)
NewsTest$NewsDesk = as.factor(NewsTest$NewsDesk)
NewsTrain$SectionName = as.factor(NewsTrain$SectionName)
NewsTest$SectionName = as.factor(NewsTest$SectionName)
NewsTrain$SubsectionName = as.factor(NewsTrain$SubsectionName)
NewsTest$SubsectionName = as.factor(NewsTest$SubsectionName)
# Create a corpus from the headline variable
# CorpusHeadline = Corpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
# CorpusHeadline = tm_map(CorpusHeadline, tolower)
# CorpusHeadline = tm_map(CorpusHeadline, PlainTextDocument)
# CorpusHeadline = tm_map(CorpusHeadline, removePunctuation)
# CorpusHeadline = tm_map(CorpusHeadline, removeWords, stopwords("english"))
# CorpusHeadline = tm_map(CorpusHeadline, stemDocument)
# dtm = DocumentTermMatrix(CorpusHeadline)
# sparse = removeSparseTerms(dtm, 0.99)
# HeadlineWords = as.data.frame(as.matrix(sparse))
# colnames(HeadlineWords) = make.names(colnames(HeadlineWords))
# HeadlineWordsTrain = head(HeadlineWords, nrow(NewsTrain))
# HeadlineWordsTest = tail(HeadlineWords, nrow(NewsTest))
# Create a corpus from the snippet variable
CorpusSnippet = Corpus(VectorSource(c(NewsTrain$Snippet, NewsTest$Snippet)))
CorpusSnippet = tm_map(CorpusSnippet, tolower)
CorpusSnippet = tm_map(CorpusSnippet, PlainTextDocument)
CorpusSnippet = tm_map(CorpusSnippet, removePunctuation)
CorpusSnippet = tm_map(CorpusSnippet, removeWords, stopwords("english"))
CorpusSnippet = tm_map(CorpusSnippet, stemDocument)
dtmSnippet = DocumentTermMatrix(CorpusSnippet)
sparseSnippet = removeSparseTerms(dtmSnippet, 0.99)
SnippetWords = as.data.frame(as.matrix(sparseSnippet))
colnames(SnippetWords) = make.names(colnames(SnippetWords))
SnippetWordsTrain = head(SnippetWords, nrow(NewsTrain))
SnippetWordsTest = tail(SnippetWords, nrow(NewsTest))
SnippetWordsTrain$Popular = NewsTrain$Popular
SnippetWordsTest$Popular = NewsTest$Popular
SnippetWordsTrain$WordCount = NewsTrain$WordCount
SnippetWordsTest$WordCount = NewsTest$WordCount
SnippetWordsTrain$NewsDesk = NewsTrain$NewsDesk
SnippetWordsTest$NewsDesk = NewsTest$NewsDesk
SnippetWordsTrain$SectionName = NewsTrain$SectionName
SnippetWordsTest$SectionName = NewsTest$SectionName
SnippetWordsTrain$SubsectionName = NewsTrain$SubsectionName
SnippetWordsTest$SubsectionName = NewsTest$SubsectionName
SnippetWordsTrain$Weekday = NewsTrain$Weekday
SnippetWordsTest$NewsDesk = NewsTest$NewsDesk
# CorpusAbstract = Corpus(VectorSource(c(NewsTrain$Abstract, NewsTest$Abstract)))
# CorpusAbstract = tm_map(CorpusAbstract, tolower)
# CorpusAbstract = tm_map(CorpusAbstract, PlainTextDocument)
# CorpusAbstract = tm_map(CorpusAbstract, removePunctuation)
# CorpusAbstract = tm_map(CorpusAbstract, removeWords, stopwords("english"))
# CorpusAbstract = tm_map(CorpusAbstract, stemDocument)
# dtmAbstract = DocumentTermMatrix(CorpusAbstract)
# sparseAbstract = removeSparseTerms(dtmAbstract, 0.99)
# AbstractWords = as.data.frame(as.matrix(sparseAbstract))
# colnames(AbstractWords) = make.names(colnames(AbstractWords))
# AbstractWordsTrain = head(AbstractWords, nrow(NewsTrain))
# AbstractWordsTest = tail(AbstractWords, nrow(NewsTest))
# Create The Model
# SimpleMod = glm(Popular ~ ., data=SnippetWordsTrain, family=binomial)
SimpleMod = rpart(Popular ~ ., data=SnippetWordsTrain)
# And then make predictions on the test set:
PredTest = predict(SimpleMod, newdata=SnippetWordsTest)
PredTrain = predict(SimpleMod, newdata=SnippetWordsTrain)
table(PredTrain>0.5, SnippetWordsTrain$Popular)
# Prepare a submission file for Kaggle
MySubmission = data.frame(UniqueID = NewsTest$UniqueID, Probability1 = PredTest)
write.csv(MySubmission, "SubmissionSimpleLog2.csv", row.names=FALSE)
 library(tm)
library(rpart)
# Read the data into R
NewsTrain = read.csv("NYTimesBlogTrain.csv", stringsAsFactors=FALSE)
NewsTest = read.csv("NYTimesBlogTest.csv", stringsAsFactors=FALSE)
# Preprocess dates
NewsTrain$PubDate = strptime(NewsTrain$PubDate, "%Y-%m-%d %H:%M:%S")
NewsTrain$Weekday = NewsTrain$PubDate$wday
NewsTest$PubDate = strptime(NewsTest$PubDate, "%Y-%m-%d %H:%M:%S")
NewsTest$Weekday = NewsTest$PubDate$wday
# Create factor variables
NewsTrain$NewsDesk = as.factor(NewsTrain$NewsDesk)
NewsTest$NewsDesk = as.factor(NewsTest$NewsDesk)
NewsTrain$SectionName = as.factor(NewsTrain$SectionName)
NewsTest$SectionName = as.factor(NewsTest$SectionName)
NewsTrain$SubsectionName = as.factor(NewsTrain$SubsectionName)
NewsTest$SubsectionName = as.factor(NewsTest$SubsectionName)
# Create a corpus from the headline variable
# CorpusHeadline = Corpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
# CorpusHeadline = tm_map(CorpusHeadline, tolower)
# CorpusHeadline = tm_map(CorpusHeadline, PlainTextDocument)
# CorpusHeadline = tm_map(CorpusHeadline, removePunctuation)
# CorpusHeadline = tm_map(CorpusHeadline, removeWords, stopwords("english"))
# CorpusHeadline = tm_map(CorpusHeadline, stemDocument)
# dtm = DocumentTermMatrix(CorpusHeadline)
# sparse = removeSparseTerms(dtm, 0.99)
# HeadlineWords = as.data.frame(as.matrix(sparse))
# colnames(HeadlineWords) = make.names(colnames(HeadlineWords))
# HeadlineWordsTrain = head(HeadlineWords, nrow(NewsTrain))
# HeadlineWordsTest = tail(HeadlineWords, nrow(NewsTest))
# Create a corpus from the snippet variable
CorpusSnippet = Corpus(VectorSource(c(NewsTrain$Snippet, NewsTest$Snippet)))
CorpusSnippet = tm_map(CorpusSnippet, tolower)
CorpusSnippet = tm_map(CorpusSnippet, PlainTextDocument)
CorpusSnippet = tm_map(CorpusSnippet, removePunctuation)
CorpusSnippet = tm_map(CorpusSnippet, removeWords, stopwords("english"))
CorpusSnippet = tm_map(CorpusSnippet, stemDocument)
dtmSnippet = DocumentTermMatrix(CorpusSnippet)
sparseSnippet = removeSparseTerms(dtmSnippet, 0.99)
SnippetWords = as.data.frame(as.matrix(sparseSnippet))
colnames(SnippetWords) = make.names(colnames(SnippetWords))
SnippetWordsTrain = head(SnippetWords, nrow(NewsTrain))
SnippetWordsTest = tail(SnippetWords, nrow(NewsTest))
SnippetWordsTrain$Popular = NewsTrain$Popular
SnippetWordsTest$Popular = NewsTest$Popular
SnippetWordsTrain$WordCount = NewsTrain$WordCount
SnippetWordsTest$WordCount = NewsTest$WordCount
SnippetWordsTrain$NewsDesk = NewsTrain$NewsDesk
SnippetWordsTest$NewsDesk = NewsTest$NewsDesk
SnippetWordsTrain$SectionName = NewsTrain$SectionName
SnippetWordsTest$SectionName = NewsTest$SectionName
SnippetWordsTrain$SubsectionName = NewsTrain$SubsectionName
SnippetWordsTest$SubsectionName = NewsTest$SubsectionName
SnippetWordsTrain$Weekday = NewsTrain$Weekday
SnippetWordsTest$Weekday = NewsTest$Weekday 
# CorpusAbstract = Corpus(VectorSource(c(NewsTrain$Abstract, NewsTest$Abstract)))
# CorpusAbstract = tm_map(CorpusAbstract, tolower)
# CorpusAbstract = tm_map(CorpusAbstract, PlainTextDocument)
# CorpusAbstract = tm_map(CorpusAbstract, removePunctuation)
# CorpusAbstract = tm_map(CorpusAbstract, removeWords, stopwords("english"))
# CorpusAbstract = tm_map(CorpusAbstract, stemDocument)
# dtmAbstract = DocumentTermMatrix(CorpusAbstract)
# sparseAbstract = removeSparseTerms(dtmAbstract, 0.99)
# AbstractWords = as.data.frame(as.matrix(sparseAbstract))
# colnames(AbstractWords) = make.names(colnames(AbstractWords))
# AbstractWordsTrain = head(AbstractWords, nrow(NewsTrain))
# AbstractWordsTest = tail(AbstractWords, nrow(NewsTest))
# Create The Model
# SimpleMod = glm(Popular ~ ., data=SnippetWordsTrain, family=binomial)
SimpleMod = rpart(Popular ~ ., data=SnippetWordsTrain)
# And then make predictions on the test set:
PredTest = predict(SimpleMod, newdata=SnippetWordsTest)
PredTrain = predict(SimpleMod, newdata=SnippetWordsTrain)
table(PredTrain>0.5, SnippetWordsTrain$Popular)
# Prepare a submission file for Kaggle
MySubmission = data.frame(UniqueID = NewsTest$UniqueID, Probability1 = PredTest)
write.csv(MySubmission, "SubmissionSimpleLog2.csv", row.names=FALSE)
SimpleMod = randomForest(Popular ~ ., data=SnippetWordsTrain)
# And then make predictions on the test set:
PredTest = predict(SimpleMod, newdata=SnippetWordsTest)
PredTrain = predict(SimpleMod, newdata=SnippetWordsTrain)
table(PredTrain>0.5, SnippetWordsTrain$Popular)
library(randomForest)
SimpleMod = randomForest(Popular ~ ., data=SnippetWordsTrain)
# And then make predictions on the test set:
PredTest = predict(SimpleMod, newdata=SnippetWordsTest)
PredTrain = predict(SimpleMod, newdata=SnippetWordsTrain)
table(PredTrain>0.5, SnippetWordsTrain$Popular)
PredTrain = predict(SimpleMod, newdata=SnippetWordsTrain, type = "class")
table(PredTrain>0.5, SnippetWordsTrain$Popular)
MySubmission = data.frame(UniqueID = NewsTest$UniqueID, Probability1 = PredTest)
write.csv(MySubmission, "SubmissionSimpleLog4.csv", row.names=FALSE)
km = kmeans(SnippetWordsTrain, centers = 3)
str(km)
SnippetWordsTrain[1]
SnippetWordsTrain[1,1]
SnippetWordsTrain[4,1]
SnippetWordsTrain[4,5]
SnippetWordsTrain[4,]
library(tm)
library(rpart)
library(randomForest)
# Read the data into R
NewsTrain = read.csv("NYTimesBlogTrain.csv", stringsAsFactors=FALSE)
NewsTest = read.csv("NYTimesBlogTest.csv", stringsAsFactors=FALSE)
# Preprocess dates
NewsTrain$PubDate = strptime(NewsTrain$PubDate, "%Y-%m-%d %H:%M:%S")
NewsTrain$Weekday = NewsTrain$PubDate$wday
NewsTest$PubDate = strptime(NewsTest$PubDate, "%Y-%m-%d %H:%M:%S")
NewsTest$Weekday = NewsTest$PubDate$wday
# Create factor variables
NewsTrain$NewsDesk = as.factor(NewsTrain$NewsDesk)
NewsTest$NewsDesk = as.factor(NewsTest$NewsDesk)
NewsTrain$SectionName = as.factor(NewsTrain$SectionName)
NewsTest$SectionName = as.factor(NewsTest$SectionName)
NewsTrain$SubsectionName = as.factor(NewsTrain$SubsectionName)
NewsTest$SubsectionName = as.factor(NewsTest$SubsectionName)
# Create a corpus from the headline variable
CorpusHeadline = Corpus(VectorSource(c(NewsTrain$Headline, NewsTest$Headline)))
CorpusHeadline = tm_map(CorpusHeadline, tolower)
CorpusHeadline = tm_map(CorpusHeadline, PlainTextDocument)
CorpusHeadline = tm_map(CorpusHeadline, removePunctuation)
CorpusHeadline = tm_map(CorpusHeadline, removeWords, stopwords("english"))
CorpusHeadline = tm_map(CorpusHeadline, stemDocument)
dtm = DocumentTermMatrix(CorpusHeadline)
sparse = removeSparseTerms(dtm, 0.99)
HeadlineWords = as.data.frame(as.matrix(sparse))
colnames(HeadlineWords) = make.names(colnames(HeadlineWords))
HeadlineWordsTrain = head(HeadlineWords, nrow(NewsTrain))
HeadlineWordsTest = tail(HeadlineWords, nrow(NewsTest))
HeadlineWordsTrain$Popular = NewsTrain$Popular
HeadlineWordsTest$Popular = NewsTest$Popular
HeadlineWordsTrain$WordCount = NewsTrain$WordCount
HeadlineWordsTest$WordCount = NewsTest$WordCount
HeadlineWordsTrain$NewsDesk = NewsTrain$NewsDesk
HeadlineWordsTest$NewsDesk = NewsTest$NewsDesk
HeadlineWordsTrain$SectionName = NewsTrain$SectionName
HeadlineWordsTest$SectionName = NewsTest$SectionName
HeadlineWordsTrain$SubsectionName = NewsTrain$SubsectionName
HeadlineWordsTest$SubsectionName = NewsTest$SubsectionName
HeadlineWordsTrain$Weekday = NewsTrain$Weekday
HeadlineWordsTest$Weekday = NewsTest$Weekday 
# Create a corpus from the snippet variable
CorpusSnippet = Corpus(VectorSource(c(NewsTrain$Snippet, NewsTest$Snippet)))
CorpusSnippet = tm_map(CorpusSnippet, tolower)
CorpusSnippet = tm_map(CorpusSnippet, PlainTextDocument)
CorpusSnippet = tm_map(CorpusSnippet, removePunctuation)
CorpusSnippet = tm_map(CorpusSnippet, removeWords, stopwords("english"))
CorpusSnippet = tm_map(CorpusSnippet, stemDocument)
dtmSnippet = DocumentTermMatrix(CorpusSnippet)
sparseSnippet = removeSparseTerms(dtmSnippet, 0.99)
SnippetWords = as.data.frame(as.matrix(sparseSnippet))
colnames(SnippetWords) = make.names(colnames(SnippetWords))
SnippetWordsTrain = head(SnippetWords, nrow(NewsTrain))
SnippetWordsTest = tail(SnippetWords, nrow(NewsTest))
SnippetWordsTrain$Popular = NewsTrain$Popular
SnippetWordsTest$Popular = NewsTest$Popular
SnippetWordsTrain$WordCount = NewsTrain$WordCount
SnippetWordsTest$WordCount = NewsTest$WordCount
SnippetWordsTrain$NewsDesk = NewsTrain$NewsDesk
SnippetWordsTest$NewsDesk = NewsTest$NewsDesk
SnippetWordsTrain$SectionName = NewsTrain$SectionName
SnippetWordsTest$SectionName = NewsTest$SectionName
SnippetWordsTrain$SubsectionName = NewsTrain$SubsectionName
SnippetWordsTest$SubsectionName = NewsTest$SubsectionName
SnippetWordsTrain$Weekday = NewsTrain$Weekday
SnippetWordsTest$Weekday = NewsTest$Weekday 
# CorpusAbstract = Corpus(VectorSource(c(NewsTrain$Abstract, NewsTest$Abstract)))
# CorpusAbstract = tm_map(CorpusAbstract, tolower)
# CorpusAbstract = tm_map(CorpusAbstract, PlainTextDocument)
# CorpusAbstract = tm_map(CorpusAbstract, removePunctuation)
# CorpusAbstract = tm_map(CorpusAbstract, removeWords, stopwords("english"))
# CorpusAbstract = tm_map(CorpusAbstract, stemDocument)
# dtmAbstract = DocumentTermMatrix(CorpusAbstract)
# sparseAbstract = removeSparseTerms(dtmAbstract, 0.99)
# AbstractWords = as.data.frame(as.matrix(sparseAbstract))
# colnames(AbstractWords) = make.names(colnames(AbstractWords))
# AbstractWordsTrain = head(AbstractWords, nrow(NewsTrain))
# AbstractWordsTest = tail(AbstractWords, nrow(NewsTest))
# Create The Model
# SimpleMod = glm(Popular ~ ., data=SnippetWordsTrain, family=binomial)
# SimpleMod = rpart(Popular ~ ., data=SnippetWordsTrain)
ModSnippet = rpart(Popular ~ ., data=SnippetWordsTrain)
ModHeadline = rpart(Popular ~ ., data=HeadlineWordsTrain)
# And then make predictions on the test set:
PredTest = predict(SimpleMod, newdata=SnippetWordsTest)
PredTrain1 = predict(ModSnippet , newdata=SnippetWordsTrain)
PredTrain2 = predict(ModHeadline , newdata=SnippetWordsTrain)
table(PredTrain1>0.5, SnippetWordsTrain$Popular)
table(PredTrain2>0.5, HeadlineWordsTrain$Popular)
PredTrain2 = predict(ModHeadline , newdata=HeadlineWordsTrain)
table(PredTrain2>0.5, HeadlineWordsTrain$Popular)
PredTrain1
PredTrain2
ModHeadline = glm(Popular ~ ., data=HeadlineWordsTrain)
summary(ModHeadline)
q()
